# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HAY0hbKqT0oYoPTwGnzWqrDEPqU69BEd

# connect VM to google drive
"""
#
# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools
# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
# !apt-get update -qq 2>&1 > /dev/null
# !apt-get -y install -qq google-drive-ocamlfuse fuse
# from google.colab import auth
# auth.authenticate_user()
# from oauth2client.client import GoogleCredentials
# creds = GoogleCredentials.get_application_default()
# import getpass
# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
# vcode = getpass.getpass()
# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

"""# import libraries"""

from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import itertools

"""# import data"""
#
# !mkdir -p TerenceDrive
# !google-drive-ocamlfuse TerenceDrive
import numpy as np
import os
cwd = os.getcwd()
file_name = "/fer2013.csv"
file_path = cwd + file_name

with open(file_path) as f:
    content = f.readlines()
 
lines = np.array(content) 

num_of_instances = lines.size - 1
print("number of instances: ",num_of_instances)   # 35887

"""# preprocess data"""

x_train, y_train, x_test, y_test,  y_test_confusion = [], [], [], [], []
num_classes = 7

for i in range(1,num_of_instances + 1):

    emotion, img, usage = lines[i].split(",")

    val = img.split(" ")
    pixels = np.array(val, 'float32')

    if 'PrivateTest' in usage:
        y_test_confusion.append(emotion)

    emotion = np_utils.to_categorical(emotion, num_classes)
    if 'Training' in usage:
        y_train.append(emotion)
        x_train.append(pixels)
    elif 'PrivateTest' in usage:
        y_test.append(emotion)
        x_test.append(pixels)


#pre-process data
x_train = np.array(x_train,order='K')
x_train = x_train.reshape(x_train.shape[0],48,48)
x_train = x_train.reshape(-1, 1, 48, 48)/255         # each pixel range (0,1)
y_train = np.array(y_train,order='K')                # length = 28709

x_test = np.array(x_test,order='K')
x_test = x_test.reshape(x_test.shape[0],48,48)
x_test = x_test.reshape(-1, 1, 48, 48)/255
y_test = np.array(y_test,order='K')

"""# image augmentation"""

gen = ImageDataGenerator(featurewise_center=True,
     samplewise_center=False,
     featurewise_std_normalization=True,
     samplewise_std_normalization=False,
     zca_whitening=False,
     rotation_range=45,
     width_shift_range=0.2,
     height_shift_range=0.2,
     shear_range=0.,
     zoom_range=[.8, 1],
     channel_shift_range=0,
     fill_mode='nearest',
     cval=0.,
     horizontal_flip=True,
     vertical_flip=True,
    # rescale=1/255.,
     data_format = "channels_first")

"""# build three models"""

# model one: CNN-VGG10
model_vgg10 = Sequential()

# Conv layer 1 (1 * 3-32)output (32, 48, 48)
model_vgg10.add(Convolution2D(
        nb_filter = 32,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
        input_shape = (1,        # channels
                       48,48),   # height & width
))
model_vgg10.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg10.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 2 (1 * 3-64)output (32, 48, 48)
model_vgg10.add(Convolution2D(
        nb_filter = 64,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg10.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg10.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 3 (2 * 3-128)output (32, 48, 48)
model_vgg10.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg10.add(Activation('relu'))
model_vgg10.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg10.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg10.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 4 (3 * 3-256) output (32, 48, 48)
model_vgg10.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg10.add(Activation('relu'))
model_vgg10.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg10.add(Activation('relu'))
model_vgg10.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg10.add(Activation('relu'))

# 2 fully connected layers
model_vgg10.add(Flatten())
model_vgg10.add(Dense(256))
model_vgg10.add(Activation('relu'))
model_vgg10.add(Dropout(0.5))
model_vgg10.add(Dense(256))
model_vgg10.add(Activation('relu'))
model_vgg10.add(Dropout(0.5))

# output layer to shape (7) for 7 classes
model_vgg10.add(Dense(7))
model_vgg10.add(Activation('softmax'))

# build model two: CNN-VGG12
model_vgg12 = Sequential()

# Conv layer 1 (2 * 3-32)output (32, 48, 48)
model_vgg12.add(Convolution2D(
        nb_filter = 32,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
        input_shape = (1,        # channels
                       48,48),   # height & width
))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Convolution2D(
        nb_filter = 32,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg12.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 2 (2 * 3-64)output (32, 48, 48)
model_vgg12.add(Convolution2D(
        nb_filter = 64,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Convolution2D(
        nb_filter = 64,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg12.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 3 (2 * 3-128)output (32, 48, 48)
model_vgg12.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg12.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 4 (3 * 3-256) output (32, 48, 48)
model_vgg12.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg12.add(Activation('relu'))

# 2 fully connected layers
model_vgg12.add(Flatten())
model_vgg12.add(Dense(256))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Dropout(0.5))
model_vgg12.add(Dense(256))
model_vgg12.add(Activation('relu'))
model_vgg12.add(Dropout(0.5))

# output layer to shape (7) for 7 classes
model_vgg12.add(Dense(7))
model_vgg12.add(Activation('softmax'))

# build model three: CNN-VGG14
model_vgg14 = Sequential()

# Conv layer 1 (2 * 3-32)output (32, 48, 48)
model_vgg14.add(Convolution2D(
        nb_filter = 32,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
        input_shape = (1,        # channels
                       48,48),   # height & width
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 32,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg14.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 2 (2 * 3-64)output (32, 48, 48)
model_vgg14.add(Convolution2D(
        nb_filter = 64,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 64,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg14.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 3 (3 * 3-128)output (32, 48, 48)
model_vgg14.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model_vgg14.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method
))

# Conv layer 4 (4 * 3-256) output (32, 48, 48)
model_vgg14.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model_vgg14.add(Activation('relu'))

# 2 fully connected layers
model_vgg14.add(Flatten())
model_vgg14.add(Dense(256))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Dropout(0.5))
model_vgg14.add(Dense(256))
model_vgg14.add(Activation('relu'))
model_vgg14.add(Dropout(0.5))

# output layer to shape (7) for 7 classes
model_vgg14.add(Dense(7))
model_vgg14.add(Activation('softmax'))

"""# train three models"""

epochs = 1500
batch_size = 256
train_generator = gen.flow(x_train, y_train, batch_size = batch_size)

# VGG10
# model_vgg10.compile(optimizer = Adam(lr = 1e-4),
#               loss = 'categorical_crossentropy',
#               metrics = ['accuracy'])
#
# history_vgg10 =  model_vgg10.fit_generator(train_generator, steps_per_epoch=len(x_train)//batch_size, epochs=epochs, validation_data= (x_test,y_test))

# VGG12
# model_vgg12.compile(optimizer = Adam(lr = 1e-4),
#               loss = 'categorical_crossentropy',
#               metrics = ['accuracy'])
#
# history_vgg12 =  model_vgg12.fit_generator(train_generator, steps_per_epoch=len(x_train)//batch_size, epochs=epochs, validation_data= (x_test,y_test))

# VGG14
model_vgg14.compile(optimizer = Adam(lr = 1e-4),
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

history_vgg14 =  model_vgg14.fit_generator(train_generator, steps_per_epoch=len(x_train)//batch_size, epochs=epochs, validation_data= (x_test,y_test))

"""# plot graph"""

plt.plot(history_vgg14.history['acc'])
plt.plot(history_vgg14.history['val_acc'])
#plt.plot(history_two.history['val_acc'])
#plt.plot(history_two.history['loss'])
#plt.plot(history_three.history['loss'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training','test'], loc='upper left')
plt.show()

plt.plot(history_vgg14.history['loss'])
plt.plot(history_vgg14.history['val_loss'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training','test'], loc='upper left')
plt.show()

"""# confusion matrix"""

class_names = ['0(Angry)', '1(Disgust)', '2(Fear)', '3(Happy)', '4(Sad)', '5(Surprise)', '6(Neutral)']

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')



# Plot non-normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix, classes=class_names,
#                       title='Confusion matrix, without normalization')
#
# # Plot normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,
#                       title='Normalized confusion matrix')
#
# plt.show()

# vgg10
# y_pred_vgg10 = model_vgg10.predict_classes(x_test)
# # Compute confusion matrix
# cnf_matrix_vgg10 = confusion_matrix( np.array(y_test_confusion,dtype=int), y_pred_vgg10)
# np.set_printoptions(precision=2)
# cnf_matrix__accuracy_vgg10 = cnf_matrix_vgg10.astype('float') / cnf_matrix_vgg10.sum(axis=1)[:, np.newaxis]
# # Plot non-normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix_vgg10, classes=class_names,
#                       title='Confusion matrix, without normalization')
#
# # Plot normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix_vgg10, classes=class_names, normalize=True,
#                       title='Normalized confusion matrix')
#
# plt.show()
#
# # vgg12
# y_pred_vgg12 = model_vgg12.predict_classes(x_test)
# # Compute confusion matrix
# cnf_matrix_vgg12 = confusion_matrix( np.array(y_test_confusion,dtype=int), y_pred_vgg12)
# np.set_printoptions(precision=2)
# cnf_matrix__accuracy_vgg12 = cnf_matrix_vgg12.astype('float') / cnf_matrix_vgg12.sum(axis=1)[:, np.newaxis]
# # Plot non-normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix_vgg12, classes=class_names,
#                       title='Confusion matrix, without normalization')
#
# # Plot normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix_vgg12, classes=class_names, normalize=True,
#                       title='Normalized confusion matrix')
#
# plt.show()

# vgg14
y_pred_vgg14 = model_vgg14.predict_classes(x_test)
# Compute confusion matrix
cnf_matrix_vgg14 = confusion_matrix( np.array(y_test_confusion,dtype=int), y_pred_vgg14)
np.set_printoptions(precision=2)
cnf_matrix__accuracy_vgg14 = cnf_matrix_vgg14.astype('float') / cnf_matrix_vgg14.sum(axis=1)[:, np.newaxis]
# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix_vgg14, classes=class_names,
                      title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix_vgg14, classes=class_names, normalize=True,
                      title='Normalized confusion matrix')

plt.show()

np.savetxt('vgg14_result.txt', y_pred_vgg14)




"""# ensemble"""
#
# y_pre = np.empty(len(x_test))
# for i in range(0,len(x_test)):
#     if ((y_pred_vgg10[i] == y_pred_vgg12[i]) or (y_pred_vgg10[i] == y_pred_vgg14[i])):
#         y_pre[i] = y_pred_vgg10[i]
#     elif (y_pred_vgg12[i] == y_pred_vgg14[i]):
#         y_pre[i] = y_pred_vgg12[i]
#     elif ((cnf_matrix__accuracy_vgg10[y_pred_vgg10[i]][y_pred_vgg10[i]] >
#             cnf_matrix__accuracy_vgg12[y_pred_vgg12[i]][y_pred_vgg12[i]]) and
#           (cnf_matrix__accuracy_vgg10[y_pred_vgg10[i]][y_pred_vgg10[i]] >
#            cnf_matrix__accuracy_vgg14[y_pred_vgg14[i]][y_pred_vgg14[i]])):
#             y_pre[i] = y_pred_vgg10[i]
#     elif(cnf_matrix__accuracy_vgg12[y_pred_vgg12[i]][y_pred_vgg12[i]] >
#             cnf_matrix__accuracy_vgg14[y_pred_vgg14[i]][y_pred_vgg14[i]]):
#         y_pre[i] = y_pred_vgg12[i]
#     else:
#         y_pre[i] = y_pred_vgg14[i]
#
# # test ensemble accuarcy
# counts = 0
# y_test_confusion = np.array(y_test_confusion, 'float32')
# for i in range(0, len(y_pre)):
#      if (y_pre[i] == y_test_confusion[i]):
#          counts = counts + 1
# ensemble_accuracy = counts/len(y_pre)
# print(ensemble_accuracy * 100, '%')
#
# y_pre
#
# y_test_confusion
#
# # ensemble confusion matrix
# # Compute confusion matrix
# cnf_matrix = confusion_matrix( np.array(y_test_confusion,dtype=int), y_pre)
# np.set_printoptions(precision=2)
# # Plot non-normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix, classes=class_names,
#                       title='Confusion matrix, without normalization')
#
# # Plot normalized confusion matrix
# plt.figure()
# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,
#                       title='Normalized confusion matrix')
#
# plt.show()