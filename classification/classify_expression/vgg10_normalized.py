# -*- coding: utf-8 -*-
"""vgg10_normalized.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N9Rohcwnf9-VJUJ3-aQN-fSTo_0uxVs_

# connect VM to google drive
"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

"""# import libraries"""

import numpy as np
import tensorflow as tf
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, AveragePooling2D,Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import itertools

"""# get data"""

!mkdir -p TerenceDrive
!google-drive-ocamlfuse TerenceDrive
import numpy as np
with open("TerenceDrive/Colab Notebooks/fer2013.csv") as f:
    content = f.readlines()
 
lines = np.array(content) 
 
num_of_instances = lines.size - 1
print("number of instances: ",num_of_instances)   # 35887

"""# pre_process data"""

x_train, y_train, x_test, y_test,  y_test_confusion = [], [], [], [], []
num_classes = 7
 
for i in range(1,num_of_instances + 1):
 emotion, img, usage = lines[i].split(",")
 
 val = img.split(" ")
 pixels = np.array(val, 'float32')
 
 if 'PublicTest' in usage:
     y_test_confusion.append(emotion)
 
 emotion = np_utils.to_categorical(emotion, num_classes)
 if 'Training' in usage:
     y_train.append(emotion)
     x_train.append(pixels)
 elif 'PublicTest' in usage:
     y_test.append(emotion)
     x_test.append(pixels)

# draw the ordinal figure
plt.imshow(x_train[2].reshape((48,48)))
plt.show() 

#pre-process data
x_train = np.array(x_train,order='K')
x_train = x_train.reshape(x_train.shape[0],48,48)
x_train = x_train.reshape(-1, 1, 48, 48)/255
y_train = np.array(y_train,order='K')                # length = 28709

x_test = np.array(x_test,order='K')
x_test = x_test.reshape(x_test.shape[0],48,48)
x_test = x_test.reshape(-1, 1, 48, 48)/255
y_test = np.array(y_test,order='K')
print('a')

"""# build CNN-BKVGG10 model"""

# build CNN-BKVGG12
model = Sequential()

# Conv layer 1 (1 * 3-32)output (32, 48, 48)
model.add(Convolution2D(
        nb_filter = 32,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
        input_shape = (1,        # channels
                       48,48),   # height & width
))
model.add(Activation('relu')) 

# maxpooling (2*2, stride = 2)
model.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method 
))

# Conv layer 2 (1 * 3-64)output (32, 48, 48)
model.add(Convolution2D(
        nb_filter = 64,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method 
))

# Conv layer 3 (2 * 3-128)output (32, 48, 48)
model.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model.add(Activation('relu')) 
model.add(Convolution2D(
        nb_filter = 128,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model.add(Activation('relu'))

# maxpooling (2*2, stride = 2)
model.add(MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2),
        border_mode = 'same',    # padding method 
))

# Conv layer 4 (3 * 3-256) output (32, 48, 48)
model.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model.add(Activation('relu')) 
model.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model.add(Activation('relu'))
model.add(Convolution2D(
        nb_filter = 256,
        nb_row = 3,
        nb_col = 3,
        strides = (1,1),
        border_mode = 'same',    # padding method
))
model.add(Activation('relu'))

# 2 fully connected layers
model.add(Flatten())
model.add(Dense(256))
model.add(Activation('relu'))
#model.add(Dropout(0.2))
model.add(Dense(256))
model.add(Activation('relu'))
#model.add(Dropout(0.2))

# output layer to shape (7) for 7 classes
model.add(Dense(7))
model.add(Activation('softmax'))

"""# Train the model"""

# train the model
""""
gen = ImageDataGenerator(featurewise_center=True,
     samplewise_center=False,
     featurewise_std_normalization=True,
     samplewise_std_normalization=False,
     zca_whitening=False,
     rotation_range=10,
     width_shift_range=0,
     height_shift_range=0,
     shear_range=0.,
     zoom_range=[.8, 1],
     channel_shift_range=0,
     fill_mode='nearest',
     cval=0.,
     horizontal_flip=True,
     vertical_flip=False,
     rescale=1/255.,
     data_format = "channels_first")
"""

gen = ImageDataGenerator(data_format = "channels_first",featurewise_center=True,featurewise_std_normalization=True, )
batch_size = 32
epochs = 100
train_generator = gen.flow(x_train, y_train, batch_size = batch_size)
 
model.compile(loss='categorical_crossentropy'
    , optimizer = Adam(lr = 1e-4)
    , metrics=['accuracy'])

#model.fit_generator(train_generator, steps_per_epoch=len(x_train)//batch_size, epochs=epochs, validation_data = x_test.all() )
#train_score = model.evaluate(x_train, y_train, verbose=0)
#print('Train loss:', train_score[0])
#print('Train accuracy:', 100*train_score[1],'%')

# evaluate the model 
#test_score = model.evaluate(x_test, y_test, verbose=0)
#print('Test loss:', test_score[0])
#print('Test accuracy:', 100*test_score[1],'%')

for i in range (10000):
  model.fit_generator(train_generator, steps_per_epoch=len(x_train)//batch_size, epochs=1)
  train_score = model.evaluate(x_train, y_train, verbose=0)
  print('Train loss:', train_score[0])
  print('Train accuracy:', 100*train_score[1],'%')

# evaluate the model 
  test_score = model.evaluate(x_test, y_test, verbose=0)
  print('Test loss:', test_score[0])
  print('Test accuracy:', 100*test_score[1],'%')

"""# confusion matrix"""

class_names = ['0(Angry)', '1(Disgust)', '2(Fear)', '3(Happy)', '4(Sad)', '5(Surprise)', '6(Neutral)']
y_pred = model.predict_classes(x_test)

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Compute confusion matrix
cnf_matrix = confusion_matrix( np.array(y_test_confusion,dtype=int), y_pred)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=class_names,
                      title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,
                      title='Normalized confusion matrix')

plt.show()

# evaluate the model 
test_score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', test_score[0])
print('Test accuracy:', 100*test_score[1],'%')